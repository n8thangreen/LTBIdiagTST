---
title: "Dual test (TST T-SPOT.TB) decision tree"
author: "Nathan Green, Imperial College London"
date: "11/12/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


We will replicate the Excel TB TST-T-SPOT.TB cost-effectiveness model.
(File name `lasttree.xls`.)


### Set-up

```{r warning=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(tibble)
library(reshape2)
library(treeSimR)
library(assertthat)
library(CEdecisiontree)
library(purrr)
library(treeSimR)
```

Load in the data.

```{r}
load(here::here("data", "params.RData"))
load(here::here("data", "trees.RData"))
```

This included the tree structure variables, the cost and probability arrays, the mapping arrays that inform which nodes have which label with have what cost.

To demonstrate, let us look at the TST and T-SPOT scenario.
The decision tree is defined in terms of parents and children in a list.

```{r}
head(TST_TSPOT_tree, 5)
```

It looks like this for the single test decision tree

![](plots/numbered_nodes_tree_SINGLE_TEST.jpg)

In order to assign values to the tree we first transform this to a (sparse) matrix format.

```{r}
# probs <- child_list_to_transmat(TST_tree)
# probs <- child_list_to_transmat(QFT_tree)
# probs <- child_list_to_transmat(TSPOT_tree)
# probs <- child_list_to_transmat(TST_QFT_tree)
probs <- child_list_to_transmat(TST_TSPOT_tree)
head(probs)

empty_transmat <- as_tibble(matrix(NA_real_,
                                   nrow = nrow(probs), ncol = ncol(probs)),
                            .name_repair = "minimal")
```

Next, we specify the labels for each of the edge (or correspondingly to node).
We need to do this separately for the probabilities and costs.

```{r}
# pname_from_to <- TST_pname_from_to
# pname_from_to <- QFT_pname_from_to
# pname_from_to <- TSPOT_pname_from_to
# pname_from_to <- TST_QFT_pname_from_to
pname_from_to <- TST_TSPOT_pname_from_to
pname_from_to
```

```{r}
# cname_from_to <- TST_cname_from_to
# cname_from_to <- QFT_cname_from_to
# cname_from_to <- TSPOT_cname_from_to
# cname_from_to <- TST_QFT_cname_from_to
cname_from_to <- TST_TSPOT_cname_from_to
cname_from_to
```


### Insert probabilities into decision tree

Now that we've set-up the framework for the decision tree, we can assign the input data to it.
The probability data is in the form of a list (this is useful for when we want to sample from a distributuion later).
Lets transform to an array.

```{r warning=FALSE, message=FALSE}
label_probs_long <-
  as_tibble(label_probs) %>%
  melt(value.name = "prob",
       variable.name = "name")
```

Insert the appropriate probabilities by converting the transition matrix to long format, matching branches to labels, matching labels to probabilities and then filling in missing probabilities so that pairs of branches sum to one.

```{r warning=FALSE, message=FALSE}
probs_new <-
  probs %>%
  transmat_to_long() %>%
  match_branch_to_label(pname_from_to) %>%
  match_branchlabel_to_prob(label_probs_long) %>%
  fill_complementary_probs()
probs_new
```

Finally, we insert these new probabilities in to the decision tree.

```{r}
probs <- CEdecisiontree:::insert_to_probmat(dat = probs_new,
                                            mat = empty_transmat)
head(probs)
```


### Insert costs into decision tree

We essentially do the same thing now for costs.

```{r warning=FALSE, message=FALSE}
label_cost_long <-
  as_tibble(label_costs) %>%
  melt(value.name = "cost",
       variable.name = "name")

head(label_cost_long)
```

Join the cost names and their associated branches in to a single array.

```{r warning=FALSE, message=FALSE}
costs_names <-
  merge(cname_from_to, label_cost_long,
        by = "name", all.x = TRUE) %>%
  mutate(from = as.numeric(as.character(from)),
         to = as.numeric(as.character(to)))
costs_names
```

Finally, we insert these costs in to the decision tree.

```{r}
costs <- CEdecisiontree:::insert_to_costmat(dat = costs_names,
                                            mat = empty_transmat)
head(costs)
```


### Run model

See the `CEdecisiontree` package for how to use the `dectree_expected_value()` function.
Here we provide the matrix format arguments.

```{r}
res <-
  dectree_expected_values(vals = costs,
                          p = probs)


res[1] + label_costs$`TB special nurse visit` #44.31
```


#### Deterministic sensitivity analysis

Simply repeating the same set of values, we can demonstrate running multiple tree calculations.
We use show how to use the long format to specify the tree as the input argument to `dectree_expected_value()`.

```{r warning=FALSE, message=FALSE}
# list of deterministic scenarios

all_long <-
  merge(costs_names, probs_new,
        all = TRUE, by = c("from", "to"),
        suffixes = c(".cost", ".prob")) %>%
  rename(vals = cost)

head(all_long)

dat <- 
  all_long %>%
  select(-contains("name"))

dat <-
  list(dat,
       dat)

map(dat,
    function(x) dectree_expected_values(define_model(dat_long = x)))
```


#### Probabilistic sensitivity analysis

We first define the decision tree.
The difference to previous trees is that we now use the _list-column_ feature to define distributions rather than point values.

For the _backwards_ model i.e. with PPV and NPV:
```{r}
             
costs_SA <-
  tibble::tribble(~name.cost,               ~vals,
                  "TST",                    list(distn = "unif", params = c(min=9.31, max=37.24)),    
                  "TB special nurse visit", list(distn = "unif", params = c(min=22.15, max=66.23)),  
                  "TSPOT",                  list(distn = "unif", params = c(min=18.06, max=68.23)),   
                  "Total Cost of positive screening",  list(distn = "unif", params = c(min=233.17, max=247.28)), 
                  "Hep",                    list(distn = "unif", params = c(min=366.06, max=1464.25)), 
                  #
                  "Total (complete)",       list(distn = "unif", params = c(min=169.68, max=169.68)),
                  "Total (incomplete)",     list(distn = "unif", params = c(min=84.84, max=84.84)))

probs_SA <-
  tibble::tribble(~name.prob,       ~prob,
                  "pAccept_chemo",  list(distn = "unif", params = c(min=0.5, max=1)),
                  "pHep",           list(distn = "unif", params = c(min=0.001, max=0.003)),
                  "pComp_chemo",    list(distn = "unif", params = c(min=0.5, max=0.9)),
                  #
                  "pAccept_TST",    list(distn = "unif", params = c(min=0.5, max=1)), #Campbell (2017)
                  "pTSTread",       list(distn = "unif", params = c(min=0.979, max=0.979)),
                  "TST_pos",        list(distn = "unif", params = c(min=0.534, max=0.534)),
                  "pAccept_IGRA_TST+", list(distn = "unif", params = c(min=0.995, max=0.995)),
                  
                  "pLTBI",          list(distn = "unif", params = c(min=0.326, max=0.326)),
                  "TSPOT_pos_TST+", list(distn = "unif", params = c(min=0.46, max=0.46)),
                  "PPV_TSPOT_TST+", list(distn = "unif", params = c(min=0.944, max=0.944)),
                  "NPV_TSPOT_TST+", list(distn = "unif", params = c(min=0.911, max=0.911)),
                  "PPV_TST",        list(distn = "unif", params = c(min=0.482, max=0.482)),
                  "NPV_TST",        list(distn = "unif", params = c(min=0.853, max=0.853)))
probs_SA
```

Combine the distributions with the original tree specification.

```{r}
input_SA <- 
  all_long %>% 
  select(-prob, -vals) %>% 
  dplyr::full_join(probs_SA, by = "name.prob") %>%
  dplyr::full_join(costs_SA, by = "name.cost") %>%
  as_tibble()

input_SA
```


We can now loop over this tree and generate samples of values for the given distributions.
We use the `sample_distributions()` function from my `treeSimR` package.

```{r warning=FALSE}
tree_dat_sa <- list()

for (i in 1:200) {
  
  tree_dat_sa[[i]] <-
    define_model(dat_long = 
                   data.frame(
                     from = input_SA$from,
                     to   = input_SA$to,
                     prob = lapply(input_SA$prob, sample_distributions) %>% unlist(),
                     vals = lapply(input_SA$vals, sample_distributions) %>% unlist())) %>% 
    select(-missing)
}
```


This results in a list of trees.
Now it is straightforward to map over each of these trees to obtain the total expected values

```{r}
res <- map(tree_dat_sa, .f = dectree_expected_values)
head(res)

hist(map_dbl(res, 1), breaks = 20)
```

